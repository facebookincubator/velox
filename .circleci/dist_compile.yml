# Copyright (c) Facebook, Inc. and its affiliates.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

version: 2.1


# Default pipeline parameters, which will be updated according to
# the results of the path-filtering orb
parameters:
  run-longer-expression-fuzzer:
    type: boolean
    default: false

commands:
  update-submodules:
    steps:
      - run:
          name: "Update Submodules"
          command: |
            git submodule sync --recursive
            git submodule update --init --recursive

  install-duckdb:
    steps:
      - run:
          name: "Install DuckDB 0.8.1"
          command: |
            source /opt/rh/gcc-toolset-9/enable
            set -xu
            mkdir ~/duckdb-install && cd ~/duckdb-install
            wget https://github.com/duckdb/duckdb/archive/refs/tags/v0.8.1.tar.gz
            tar -xf v0.8.1.tar.gz
            cd duckdb-0.8.1
            mkdir build && cd build
            CMAKE_FLAGS=(
              "-DBUILD_UNITTESTS=OFF"
              "-DENABLE_SANITIZER=OFF"
              "-DENABLE_UBSAN=OFF"
              "-DBUILD_SHELL=OFF"
              "-DEXPORT_DLL_SYMBOLS=OFF"
            )
            cmake ${CMAKE_FLAGS[*]}  ..
            make install -j 16

  setup-environment:
    steps:
      - run:
          name: "Setup Environment"
          command: |
            # Calculate ccache key.
            git show -s --format=%cd --date="format:%Y%m%d" $(git merge-base origin/main HEAD) | tee merge-base-date

            # Set up xml gtest output.
            mkdir -p /tmp/test_xml_output/
            echo "export XML_OUTPUT_FILE=\"/tmp/test_xml_output/\"" >> $BASH_ENV

            # Set up ccache configs.
            mkdir -p .ccache
            echo "export CCACHE_DIR=$(realpath .ccache)" >> $BASH_ENV
            ccache -sz -M 5Gi
            if [ -e /opt/rh/gcc-toolset-9/enable ]; then
              source /opt/rh/gcc-toolset-9/enable
            fi
      - restore_cache:
          name: "Restore CCache Cache"
          keys:
            - velox-ccache-debug-{{ arch }}-{{ checksum "merge-base-date" }}

  pre-steps:
    steps:
      - checkout
      - update-submodules
      - setup-environment

  post-steps:
    steps:
      - save_cache:
          name: "Save CCache Cache"
          key: velox-ccache-debug-{{ arch }}-{{ checksum "merge-base-date" }}
          paths:
            - .ccache/
      - store_artifacts:
          path: '_build/debug/.ninja_log'
      - store_test_results:
          path: '/tmp/test_xml_output/'

  build-benchmarks:
    parameters:
      binary_output:
        type: string
      benchmark_class:
        type: string
    steps:
      - run:
          name: "Build Benchmarks - << parameters.benchmark_class >>"
          command: |
            make benchmarks-basic-build NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=8
            ccache -s
            mkdir -p << parameters.binary_output >>
            cp -r --verbose _build/release/velox/benchmarks/basic/* << parameters.binary_output >>

  fuzzer-run:
    parameters:
      fuzzer_repro:
        type: string
      fuzzer_output:
        type: string
      fuzzer_name:
        type: string
      fuzzer_exe:
        type: string
      fuzzer_args:
        type: string
    steps:
      - pre-steps
      - run:
          name: Build
          command: |
            make debug NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=4
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Run << parameters.fuzzer_name >> Fuzzer"
          command: |
            eval ' << parameters.fuzzer_exe >> << parameters.fuzzer_args >> ' \
                  2>&1 | tee "<< parameters.fuzzer_output >>" || ( \
                    tail -n 1000 "<< parameters.fuzzer_output >>" ; \
                    echo "FAIL: << parameters.fuzzer_name >> run failed"; \
                    exit 1; \
                  )
                echo -e "\n << parameters.fuzzer_name >> run finished successfully."
          no_output_timeout: 120m
      - store_artifacts:
          path: << parameters.fuzzer_output >>
      - store_artifacts:
          path: << parameters.fuzzer_repro >>
      - post-steps

executors:
  build:
    docker:
      - image : ghcr.io/facebookincubator/velox-dev:circleci-avx
    resource_class: 2xlarge
    environment:
      CC:  /opt/rh/gcc-toolset-9/root/bin/gcc
      CXX: /opt/rh/gcc-toolset-9/root/bin/g++
      VELOX_DEPENDENCY_SOURCE: BUNDLED
      simdjson_SOURCE: BUNDLED
  check:
    docker:
      - image : ghcr.io/facebookincubator/velox-dev:check-avx
  macos-intel:
    macos:
      xcode: "14.3.0"
    resource_class: macos.x86.medium.gen2
  macos-m1:
    macos:
      xcode: "14.2.0"
    resource_class: macos.m1.large.gen1

jobs:
  macos-build:
    parameters:
      os:
        type: executor
    executor: << parameters.os >>
    environment:
      ICU_SOURCE: BUNDLED
      simdjson_SOURCE: BUNDLED
    steps:
      - checkout
      - update-submodules
      - restore_cache:
          name: "Restore Dependency Cache"
          # The version number in the key can be incremented
          # to manually avoid the case where bad dependencies
          # are cached, and has no other meaning.
          # If you update it, be sure to update save_cache too.
          key: velox-circleci-macos-{{ arch }}-deps-v1-{{ checksum ".circleci/config.yml" }}-{{ checksum "scripts/setup-macos.sh" }}
      - run:
          name: "Install dependencies"
          command: |
            set -xu
            mkdir -p ~/deps ~/deps-src
            curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C ~/deps
            PATH=~/deps/bin:${PATH} DEPENDENCY_DIR=~/deps-src INSTALL_PREFIX=~/deps PROMPT_ALWAYS_RESPOND=n ./scripts/setup-macos.sh
            rm -rf ~/deps/.git ~/deps/Library/Taps/  # Reduce cache size by 70%.
          no_output_timeout: 20m
      - save_cache:
          name: "Save Dependency Cache"
          # The version number in the key can be incremented
          # to manually avoid the case where bad dependencies
          # are cached, and has no other meaning.
          # If you update it, be sure to update restore_cache too.
          key: velox-circleci-macos-{{ arch }}-deps-v1-{{ checksum ".circleci/config.yml" }}-{{ checksum "scripts/setup-macos.sh" }}
          paths:
            - ~/deps
      - run:
          name: "Calculate merge-base date for CCache"
          command: git show -s --format=%cd --date="format:%Y%m%d" $(git merge-base origin/main HEAD) | tee merge-base-date
      - restore_cache:
          name: "Restore CCache cache"
          keys:
            - velox-ccache-debug-{{ arch }}-{{ checksum "merge-base-date" }}
      - run:
          name: "Build on MacOS"
          command: |
            export PATH=~/deps/bin:~/deps/opt/bison/bin:~/deps/opt/flex/bin:${PATH}
            mkdir -p .ccache
            export CCACHE_DIR=$(pwd)/.ccache
            ccache -sz -M 5Gi
            brew install openssl@1.1
            brew link --overwrite --force openssl@1.1
            export PATH="/Users/distiller/deps/opt/openssl@1.1/bin:$PATH"
            export OPENSSL_ROOT_DIR=$(brew --prefix openssl@1.1)
            cmake \
                -B _build/debug \
                -GNinja \
                -DTREAT_WARNINGS_AS_ERRORS=1 \
                -DENABLE_ALL_WARNINGS=1 \
                -DVELOX_ENABLE_PARQUET=ON \
                -DCMAKE_BUILD_TYPE=Debug \
                -DCMAKE_PREFIX_PATH=~/deps \
                -DCMAKE_CXX_COMPILER_LAUNCHER=ccache \
                -DFLEX_INCLUDE_DIR=~/deps/opt/flex/include
            ninja -C _build/debug
            ccache -s
          no_output_timeout: 1h
      - save_cache:
          name: "Save CCache cache"
          key: velox-ccache-debug-{{ arch }}-{{ checksum "merge-base-date" }}
          paths:
            - .ccache/

  linux-build:
    executor: build
    environment:
      DuckDB_SOURCE: SYSTEM
    steps:
      - pre-steps
      - install-duckdb
      - run:
          name: "Build"
          command: |
            make debug NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=5 EXTRA_CMAKE_FLAGS="-DVELOX_ENABLE_ARROW=ON"
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Run Unit Tests"
          command: |
            cd _build/debug && ctest -j 16 -VV --output-on-failure --no-tests=error
          no_output_timeout: 1h
      - store_test_results:
          path: /tmp/test_xml_output/
      - run:
          name: "Run Fuzzer Tests"
          # Run fuzzer using the built executable - we do this instead of make
          # since currently make fuzzertest tends to rebuild the project.
          command: |
            mkdir -p /tmp/fuzzer_repro/
            chmod -R 777 /tmp/fuzzer_repro
            _build/debug/velox/expression/tests/velox_expression_fuzzer_test \
                --seed ${RANDOM} \
                --enable_variadic_signatures \
                --velox_fuzzer_enable_complex_types \
                --lazy_vector_generation_ratio 0.2 \
                --velox_fuzzer_enable_column_reuse \
                --velox_fuzzer_enable_expression_reuse \
                --max_expression_trees_per_step 2 \
                --retry_with_try \
                --enable_dereference \
                --duration_sec 60 \
                --logtostderr=1 \
                --minloglevel=0 \
                --repro_persist_path=/tmp/fuzzer_repro \
            && echo -e "\n\nFuzzer run finished successfully."
          no_output_timeout: 5m
      - store_artifacts:
          path: '/tmp/fuzzer_repro'
      - run:
          name: "Run Spark Fuzzer Tests"
          command: |
            mkdir -p /tmp/spark_fuzzer_repro/
            chmod -R 777 /tmp/spark_fuzzer_repro
            _build/debug/velox/expression/tests/spark_expression_fuzzer_test \
                --seed ${RANDOM} \
                --duration_sec 60 \
                --enable_variadic_signatures \
                --lazy_vector_generation_ratio 0.2 \
                --velox_fuzzer_enable_column_reuse \
                --velox_fuzzer_enable_expression_reuse \
                --max_expression_trees_per_step 2 \
                --retry_with_try \
                --enable_dereference \
                --logtostderr=1 \
                --minloglevel=0 \
                --repro_persist_path=/tmp/spark_fuzzer_repro \
            && echo -e "\n\nSpark Fuzzer run finished successfully."
          no_output_timeout: 5m
      - store_artifacts:
          path: '/tmp/spark_fuzzer_repro'
      - run:
          name: "Run Spark Aggregate Fuzzer Tests"
          command: |
            mkdir -p /tmp/spark_aggregate_fuzzer_repro/
            chmod -R 777 /tmp/spark_aggregate_fuzzer_repro
            _build/debug/velox/functions/sparksql/fuzzer/spark_aggregation_fuzzer_test \
                --seed ${RANDOM} \
                --duration_sec 60 \
                --logtostderr=1 \
                --minloglevel=0 \
                --repro_persist_path=/tmp/spark_aggregate_fuzzer_repro \
            && echo -e "\n\nSpark Aggregation Fuzzer run finished successfully."
          no_output_timeout: 5m
      - store_artifacts:
          path: '/tmp/spark_aggregate_fuzzer_repro'
      - run:
          name: "Run Aggregate Fuzzer Tests"
          # Run aggregation fuzzer using the built executable.
          command: |
            mkdir -p /tmp/aggregate_fuzzer_repro/
            rm -rfv /tmp/aggregate_fuzzer_repro/*
            chmod -R 777 /tmp/aggregate_fuzzer_repro
            _build/debug/velox/functions/prestosql/fuzzer/velox_aggregation_fuzzer_test \
                --seed ${RANDOM} \
                --duration_sec 1800 \
                --logtostderr=1 \
                --minloglevel=0 \
                --repro_persist_path=/tmp/aggregate_fuzzer_repro \
            && echo -e "\n\nAggregation fuzzer run finished successfully."
          no_output_timeout: 5m
      - store_artifacts:
          path: '/tmp/aggregate_fuzzer_repro'
      - run:
          name: "Run Join Fuzzer Tests"
          command: |
            _build/debug/velox/exec/tests/velox_join_fuzzer_test \
                --seed ${RANDOM} \
                --duration_sec 1800 \
                --logtostderr=1 \
                --minloglevel=0 \
            && echo -e "\n\nJoin fuzzer run finished successfully."
          no_output_timeout: 5m
      - run:
          name: "Run Example Binaries"
          command: |
            find _build/debug/velox/examples/ -maxdepth 1 -type f -executable -exec "{}" \;
      - post-steps

  linux-build-release:
    executor: build
    steps:
      - pre-steps
      - run:
          name: Build
          command: |
            make release NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=8
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Run Unit Tests"
          command: |
            cd _build/release && ctest -j 16 -VV --output-on-failure --no-tests=error
          no_output_timeout: 1h
      - post-steps

  # Build with different options
  linux-build-options:
    executor: build
    steps:
      - pre-steps
      - run:
          name: "Build Velox Minimal"
          command: |
            make min_debug NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=16
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Build Velox With Benchmarks and Without Testing"
          command: |
            make benchmarks-build NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=16
          no_output_timeout: 1h
      - post-steps

  linux-adapters:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
      ICU_SOURCE: BUNDLED
      simdjson_SOURCE: BUNDLED
      DuckDB_SOURCE: SYSTEM
    steps:
      - pre-steps
      - install-duckdb
      - run:
          name: "Install Adapter Dependencies"
          command: |
            mkdir -p ~/adapter-deps/install/bin
            source /opt/rh/gcc-toolset-9/enable
            set -xu
            DEPENDENCY_DIR=~/adapter-deps PROMPT_ALWAYS_RESPOND=n ./scripts/setup-adapters.sh
      - run:
          name: "Install Minio Server"
          command: |
            set -xu
            cd ~/adapter-deps/install/bin/
            wget https://dl.min.io/server/minio/release/linux-amd64/archive/minio-20220526054841.0.0.x86_64.rpm
            rpm -i minio-20220526054841.0.0.x86_64.rpm
            rm minio-20220526054841.0.0.x86_64.rpm
      - run:
          name: "Install Hadoop Dependency"
          command: |
            set -xu
            yum -y install java-1.8.0-openjdk
      - run:
          name: Build including all Benchmarks
          command: |
            EXTRA_CMAKE_FLAGS=(
              "-DVELOX_ENABLE_BENCHMARKS=ON"
              "-DVELOX_ENABLE_ARROW=ON"
              "-DVELOX_ENABLE_PARQUET=ON"
              "-DVELOX_ENABLE_HDFS=ON"
              "-DVELOX_ENABLE_S3=ON"
              "-DVELOX_ENABLE_GCS=ON"
              "-DVELOX_ENABLE_ABFS=ON"
              "-DVELOX_ENABLE_SUBSTRAIT=ON"
              "-DVELOX_ENABLE_REMOTE_FUNCTIONS=ON"
            )
            make release EXTRA_CMAKE_FLAGS="${EXTRA_CMAKE_FLAGS[*]}" AWSSDK_ROOT_DIR=~/adapter-deps/install GCSSDK_ROOT_DIR=~/adapter-deps/install NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=8
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Run Unit Tests"
          command: |
            conda init bash
            source ~/.bashrc
            conda create -y --name testbench python=3.7
            conda activate testbench
            pip install https://github.com/googleapis/storage-testbench/archive/refs/tags/v0.36.0.tar.gz
            export LC_ALL=C
            export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk
            export HADOOP_ROOT_LOGGER="WARN,DRFA"
            export LIBHDFS3_CONF=$(pwd)/.circleci/hdfs-client.xml
            export HADOOP_HOME='/usr/local/hadoop'
            export PATH=~/adapter-deps/install/bin:/usr/local/hadoop/bin:${PATH}
            # The following is used to install Azurite in the CI for running Abfs Hive Connector unit tests.
            # Azurite is an emulator for local Azure Storage development, and it is a required component for running Abfs Hive Connector unit tests.
            # It can be installed using npm. The following is used to install Node.js and npm for Azurite installation.
            curl -sL https://rpm.nodesource.com/setup_10.x | bash -
            yum install -y nodejs
            npm install -g azurite
            cd _build/release && ctest -j 16 -VV --output-on-failure --no-tests=error
          no_output_timeout: 1h
      - post-steps

  linux-presto-fuzzer-run:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
      simdjson_SOURCE: BUNDLED
      DuckDB_SOURCE: BUNDLED
    steps:
      - fuzzer-run:
          fuzzer_output: "/tmp/fuzzer.log"
          fuzzer_repro: "/tmp/fuzzer_repro"
          fuzzer_name: "Expression"
          fuzzer_exe: "_build/debug/velox/expression/tests/velox_expression_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --lazy_vector_generation_ratio 0.2 \
          --duration_sec 1800 --enable_variadic_signatures \
          --velox_fuzzer_enable_complex_types \
          --velox_fuzzer_enable_column_reuse \
          --velox_fuzzer_enable_expression_reuse \
          --max_expression_trees_per_step 2 \
          --retry_with_try \
          --enable_dereference \
          --logtostderr=1 --minloglevel=0 \
          --repro_persist_path=/tmp/fuzzer_repro"

  linux-spark-fuzzer-run:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
      simdjson_SOURCE: BUNDLED
    steps:
      - fuzzer-run:
          fuzzer_output: "/tmp/spark_fuzzer.log"
          fuzzer_repro: "/tmp/spark_fuzzer_repro"
          fuzzer_name: "Spark"
          fuzzer_exe: "_build/debug/velox/expression/tests/spark_expression_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --duration_sec 600 --logtostderr=1 --minloglevel=0 \
          --repro_persist_path=/tmp/spark_fuzzer_repro"

  linux-spark-aggregate-fuzzer-run:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
      simdjson_SOURCE: BUNDLED
    steps:
      - fuzzer-run:
          fuzzer_output: "/tmp/spark_aggregate_fuzzer.log"
          fuzzer_repro: "/tmp/spark_aggregate_fuzzer_repro"
          fuzzer_name: "SparkAggregate"
          fuzzer_exe: "_build/debug/velox/functions/sparksql/fuzzer/spark_aggregation_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --duration_sec 600 --logtostderr=1 --minloglevel=0 \
          --repro_persist_path=/tmp/spark_aggregate_fuzzer_repro"


  linux-aggregate-fuzzer-run:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
      simdjson_SOURCE: BUNDLED
    steps:
      - fuzzer-run:
          fuzzer_output: "/tmp/aggregate_fuzzer.log"
          fuzzer_repro: "/tmp/aggregate_fuzzer_repro"
          fuzzer_name: "Aggregate"
          fuzzer_exe: "_build/debug/velox/functions/prestosql/fuzzer/velox_aggregation_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --duration_sec 3600 --logtostderr=1 --minloglevel=0 \
          --repro_persist_path=/tmp/aggregate_fuzzer_repro"

  linux-join-fuzzer-run:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
      simdjson_SOURCE: BUNDLED
    steps:
      - fuzzer-run:
          fuzzer_output: "/tmp/join_fuzzer.log"
          fuzzer_repro: "/tmp/join_fuzzer_repro"
          fuzzer_name: "Join"
          fuzzer_exe: "_build/debug/velox/exec/tests/velox_join_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --duration_sec 3600 --logtostderr=1 --minloglevel=0"

  format-check:
    executor: check
    steps:
      - checkout
      - run:
          name: Check formatting
          command: |
            if ! make format-check; then
              make format-fix
              echo -e "\n==== Apply using:"
              echo "patch -p1 \<<EOF"
              git --no-pager diff
              echo "EOF"
              false
            fi

  header-check:
    executor: check
    steps:
      - checkout
      - run:
          name: Check license headers
          command: |
            if ! make header-check; then
              make header-fix
              echo -e "\n==== Apply using:"
              echo "patch -p1 \<<EOF"
              git --no-pager diff
              echo "EOF"
              false
            fi

  doc-gen-job:
    executor: build
    steps:
      - checkout
      - update-submodules
      - add_ssh_keys:
          fingerprints:
            - "7b:24:f3:1a:b1:15:97:c6:fe:06:46:27:3e:b7:6b:96"
      - run:
          name: "Build docs and update gh-pages"
          command: |
            git config --global user.email "velox@users.noreply.github.com"
            git config --global user.name "velox"
            git checkout main
            conda init bash
            source ~/.bashrc
            conda create -y --name docgenenv python=3.7
            conda activate docgenenv
            pip install sphinx sphinx-tabs breathe sphinx_rtd_theme chardet
            source /opt/rh/gcc-toolset-9/enable
            ./scripts/gen-docs.sh docgenenv
            git checkout gh-pages
            cp -R velox/docs/_build/html/* docs
            git add docs
            if [ -n "$(git status --porcelain --untracked-files=no)" ]
            then
              git commit -m "Update documentation"
              git push
            fi



  linux-pr-fuzzer-run:
    executor: build
    steps:
      - pre-steps
      - run:
          name: "Get merge base function signatures"
          command: |
            source ~/.bashrc
            conda create -y --name pyveloxenv python=3.7
            conda activate pyveloxenv
            cp ./scripts/signature.py /tmp/signature.py
            pip install deepdiff
            git remote add upstream https://github.com/facebookincubator/velox
            git fetch upstream
            merge_base=$(git merge-base  'upstream/main' `git rev-parse HEAD`) || \
            { echo "::error::Failed to find merge_base"; exit 1; }
            echo "Merge Base: $merge_base"
            git checkout $merge_base
            git submodule update --init --recursive
            LD_LIBRARY_PATH=/usr/local/lib make python-clean
            LD_LIBRARY_PATH=/usr/local/lib make python-build
            python /tmp/signature.py export --spark spark_merge_base_signatures.json
            python /tmp/signature.py export --presto presto_merge_base_signatures.json
      - checkout
      - run:
          name: "Build"
          command: |
            make debug NUM_THREADS=8 MAX_HIGH_MEM_JOBS=4 MAX_LINK_JOBS=4 EXTRA_CMAKE_FLAGS="-DVELOX_ENABLE_ARROW=ON"
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Build and test PyVelox"
          command: |
            conda init bash
            source ~/.bashrc
            conda activate pyveloxenv
            LD_LIBRARY_PATH=/usr/local/lib make python-test
      - run:
          name: "Check and create bias function signatures"
          command: |
            source ~/.bashrc
            conda activate pyveloxenv
            pip install deepdiff
            python ./scripts/signature.py export --presto presto_pr_signatures.json
            python ./scripts/signature.py export --spark spark_pr_signatures.json
            if python ./scripts/signature.py bias presto_merge_base_signatures.json presto_pr_signatures.json /tmp/presto_bias_functions 2>&1 > /tmp/presto-err-message; \
            then echo "Presto signature check success" ; else echo "Presto signature check failed" > /tmp/presto-signature-error-code ; fi
            if python ./scripts/signature.py bias spark_merge_base_signatures.json spark_pr_signatures.json /tmp/spark_bias_functions ; \
            then echo "Spark signature check success"; else echo "Spark signature check failed" > /tmp/spark-signature-error-code ; fi

      - store_artifacts:
          path: 'presto_merge_base_signatures.json'
      - store_artifacts:
          path: 'presto_pr_signatures.json'
      - store_artifacts:
          path: 'spark_merge_base_signatures.json'
      - store_artifacts:
          path: 'spark_pr_signatures.json'
      - fuzzer-run:
          fuzzer_output: "/tmp/fuzzer.log"
          fuzzer_repro: "/tmp/fuzzer_repro"
          fuzzer_name: "Expression Bias Run"
          fuzzer_exe: "if [ -f /tmp/presto_bias_functions ]; then _build/debug/velox/expression/tests/velox_expression_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --lazy_vector_generation_ratio 0.2 \
          --assign_function_tickets  $(cat /tmp/presto_bias_functions) \
          --duration_sec 3600 --enable_variadic_signatures \
          --velox_fuzzer_enable_complex_types \
          --velox_fuzzer_enable_column_reuse \
          --velox_fuzzer_enable_expression_reuse \
          --max_expression_trees_per_step 2 \
          --retry_with_try \
          --enable_dereference \
          --logtostderr=1 --minloglevel=0 \
          --repro_persist_path=/tmp/fuzzer_repro ; fi"

      - fuzzer-run:
          fuzzer_output: "/tmp/spark_fuzzer.log"
          fuzzer_repro: "/tmp/spark_fuzzer_repro"
          fuzzer_name: "Spark Bias Run"
          fuzzer_exe: "if [ -f /tmp/spark_bias_functions ];  then _build/debug/velox/expression/tests/spark_expression_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --duration_sec 3600 --logtostderr=1 --minloglevel=0 \
                --assign_function_tickets  $(cat /tmp/spark_bias_functions) \
                --repro_persist_path=/tmp/spark_fuzzer_repro ; fi"

      - run:
          name: "Surface only Presto function signature errors if any"
          command: |
              if [ -f /tmp/presto-signature-error-code ]; then \
              echo "Incompatible changes have been made to function signatures:\n"; \
              cat /tmp/presto-err-message ; \
              exit 1 ; \
              fi


workflows:

  longer-fuzzer:
    when: << pipeline.parameters.run-longer-expression-fuzzer >>
    jobs:
      - linux-build
      - linux-pr-fuzzer-run
      - linux-build-options
      - linux-adapters
      - linux-presto-fuzzer-run
      - macos-build:
          matrix:
            parameters:
              os: [macos-intel]
      - format-check
      - header-check
      - doc-gen-job:
          filters:
            branches:
              only:
                - main
      - macos-build:
          matrix:
            parameters:
              os: [ macos-m1 ]
          filters:
            branches:
              only:
                - main

  shorter-fuzzer:
    unless: << pipeline.parameters.run-longer-expression-fuzzer >>
    jobs:
      - linux-build
      - linux-pr-fuzzer-run
      - linux-build-options
      - linux-adapters
      - macos-build:
          matrix:
            parameters:
              os: [ macos-intel ]
      - format-check
      - header-check
      - doc-gen-job:
          filters:
            branches:
              only:
                - main
      - macos-build:
          matrix:
            parameters:
              os: [ macos-m1 ]
          filters:
            branches:
              only:
                - main
