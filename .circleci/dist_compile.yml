# Copyright (c) Facebook, Inc. and its affiliates.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

version: 2.1


# Default pipeline parameters, which will be updated according to
# the results of the path-filtering orb
parameters:
  run-longer-expression-fuzzer:
    type: boolean
    default: false

commands:
  update-submodules:
    steps:
      - run:
          name: "Update Submodules"
          command: |
            git submodule sync --recursive
            git submodule update --init --recursive

  setup-environment:
    steps:
      - run:
          name: "Setup Environment"
          command: |
            # Calculate ccache key.
            git show -s --format=%cd --date="format:%Y%m%d" $(git merge-base origin/main HEAD) | tee merge-base-date

            # Set up xml gtest output.
            mkdir -p /tmp/test_xml_output/
            echo "export XML_OUTPUT_FILE=\"/tmp/test_xml_output/\"" >> $BASH_ENV

            # Set up ccache configs.
            mkdir -p .ccache
            echo "export CCACHE_DIR=$(realpath .ccache)" >> $BASH_ENV
            ccache -sz -M 5Gi
            if [ -e /opt/rh/gcc-toolset-9/enable ]; then
              source /opt/rh/gcc-toolset-9/enable
            fi
      - restore_cache:
          name: "Restore CCache Cache"
          keys:
            - velox-ccache-debug-{{ arch }}-{{ checksum "merge-base-date" }}

  pre-steps:
    steps:
      - checkout
      - update-submodules
      - setup-environment

  post-steps:
    steps:
      - save_cache:
          name: "Save CCache Cache"
          key: velox-ccache-debug-{{ arch }}-{{ checksum "merge-base-date" }}
          paths:
            - .ccache/
      - store_artifacts:
          path: '_build/debug/.ninja_log'
      - store_test_results:
          path: '/tmp/test_xml_output/'

  build-benchmarks:
    parameters:
      binary_output:
        type: string
      benchmark_class:
        type: string
    steps:
      - run:
          name: "Build Benchmarks - << parameters.benchmark_class >>"
          command: |
            make benchmarks-basic-build NUM_THREADS=8 MAX_HIGH_MEM_JOBS=4 MAX_LINK_JOBS=4
            ccache -s
            mkdir -p << parameters.binary_output >>
            cp -r --verbose _build/release/velox/benchmarks/basic/* << parameters.binary_output >>

  fuzzer-run:
    parameters:
      fuzzer_repro:
        type: string
      fuzzer_output:
        type: string
      fuzzer_name:
        type: string
      fuzzer_exe:
        type: string
      fuzzer_args:
        type: string
    steps:
      - pre-steps
      - run:
          name: Build
          command: |
            make debug NUM_THREADS=8 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=4
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Run << parameters.fuzzer_name >> Fuzzer"
          command: |
            eval ' << parameters.fuzzer_exe >> << parameters.fuzzer_args >> ' \
                  2>&1 | tee "<< parameters.fuzzer_output >>" || ( \
                    tail -n 1000 "<< parameters.fuzzer_output >>" ; \
                    echo "FAIL: << parameters.fuzzer_name >> run failed"; \
                    exit 1; \
                  )
                echo -e "\n << parameters.fuzzer_name >> run finished successfully."
          no_output_timeout: 120m
      - store_artifacts:
          path: << parameters.fuzzer_output >>
      - store_artifacts:
          path: << parameters.fuzzer_repro >>
      - post-steps

executors:
  build:
    docker:
      - image : ghcr.io/facebookincubator/velox-dev:circleci-avx
    resource_class: 2xlarge
    environment:
      CC:  /opt/rh/gcc-toolset-9/root/bin/gcc
      CXX: /opt/rh/gcc-toolset-9/root/bin/g++
      VELOX_DEPENDENCY_SOURCE: BUNDLED
      simdjson_SOURCE: BUNDLED
  check:
    docker:
      - image : ghcr.io/facebookincubator/velox-dev:check-avx

jobs:
  linux-build:
    executor: build
    environment:
      DuckDB_SOURCE: SYSTEM
    steps:
      - pre-steps
      - run:
          name: "Build"
          command: |
            make debug NUM_THREADS=8 MAX_HIGH_MEM_JOBS=4 MAX_LINK_JOBS=4 EXTRA_CMAKE_FLAGS="-DVELOX_ENABLE_ARROW=ON"
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Run Unit Tests"
          command: |
            cd _build/debug && ctest -j 16 -VV --output-on-failure --no-tests=error
          no_output_timeout: 1h
      - store_test_results:
          path: /tmp/test_xml_output/
      - run:
          name: "Run Fuzzer Tests"
          # Run fuzzer using the built executable - we do this instead of make
          # since currently make fuzzertest tends to rebuild the project.
          command: |
            mkdir -p /tmp/fuzzer_repro/
            chmod -R 777 /tmp/fuzzer_repro
            _build/debug/velox/expression/tests/velox_expression_fuzzer_test \
                --seed ${RANDOM} \
                --enable_variadic_signatures \
                --velox_fuzzer_enable_complex_types \
                --lazy_vector_generation_ratio 0.2 \
                --velox_fuzzer_enable_column_reuse \
                --velox_fuzzer_enable_expression_reuse \
                --max_expression_trees_per_step 2 \
                --retry_with_try \
                --enable_dereference \
                --duration_sec 60 \
                --logtostderr=1 \
                --minloglevel=0 \
                --repro_persist_path=/tmp/fuzzer_repro \
            && echo -e "\n\nFuzzer run finished successfully."
          no_output_timeout: 5m
      - store_artifacts:
          path: '/tmp/fuzzer_repro'
      - run:
          name: "Run Spark Fuzzer Tests"
          command: |
            mkdir -p /tmp/spark_fuzzer_repro/
            chmod -R 777 /tmp/spark_fuzzer_repro
            _build/debug/velox/expression/tests/spark_expression_fuzzer_test \
                --seed ${RANDOM} \
                --duration_sec 60 \
                --enable_variadic_signatures \
                --lazy_vector_generation_ratio 0.2 \
                --velox_fuzzer_enable_column_reuse \
                --velox_fuzzer_enable_expression_reuse \
                --max_expression_trees_per_step 2 \
                --retry_with_try \
                --enable_dereference \
                --logtostderr=1 \
                --minloglevel=0 \
                --repro_persist_path=/tmp/spark_fuzzer_repro \
            && echo -e "\n\nSpark Fuzzer run finished successfully."
          no_output_timeout: 5m
      - store_artifacts:
          path: '/tmp/spark_fuzzer_repro'
      - run:
          name: "Run Spark Aggregate Fuzzer Tests"
          command: |
            mkdir -p /tmp/spark_aggregate_fuzzer_repro/
            chmod -R 777 /tmp/spark_aggregate_fuzzer_repro
            _build/debug/velox/functions/sparksql/fuzzer/spark_aggregation_fuzzer_test \
                --seed ${RANDOM} \
                --duration_sec 60 \
                --logtostderr=1 \
                --minloglevel=0 \
                --repro_persist_path=/tmp/spark_aggregate_fuzzer_repro \
            && echo -e "\n\nSpark Aggregation Fuzzer run finished successfully."
          no_output_timeout: 5m
      - store_artifacts:
          path: '/tmp/spark_aggregate_fuzzer_repro'
      - run:
          name: "Run Aggregate Fuzzer Tests"
          # Run aggregation fuzzer using the built executable.
          command: |
            mkdir -p /tmp/aggregate_fuzzer_repro/
            rm -rfv /tmp/aggregate_fuzzer_repro/*
            chmod -R 777 /tmp/aggregate_fuzzer_repro
            _build/debug/velox/functions/prestosql/fuzzer/velox_aggregation_fuzzer_test \
                --seed ${RANDOM} \
                --duration_sec 1800 \
                --logtostderr=1 \
                --minloglevel=0 \
                --repro_persist_path=/tmp/aggregate_fuzzer_repro \
            && echo -e "\n\nAggregation fuzzer run finished successfully."
          no_output_timeout: 5m
      - store_artifacts:
          path: '/tmp/aggregate_fuzzer_repro'
      - run:
          name: "Run Join Fuzzer Tests"
          command: |
            _build/debug/velox/exec/tests/velox_join_fuzzer_test \
                --seed ${RANDOM} \
                --duration_sec 1800 \
                --logtostderr=1 \
                --minloglevel=0 \
            && echo -e "\n\nJoin fuzzer run finished successfully."
          no_output_timeout: 5m
      - run:
          name: "Run Example Binaries"
          command: |
            find _build/debug/velox/examples/ -maxdepth 1 -type f -executable -exec "{}" \;
      - post-steps

  linux-build-release:
    executor: build
    steps:
      - pre-steps
      - run:
          name: Build
          command: |
            make release NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=8
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Run Unit Tests"
          command: |
            cd _build/release && ctest -j 16 -VV --output-on-failure --no-tests=error
          no_output_timeout: 1h
      - post-steps

  # Build with different options
  linux-build-options:
    executor: build
    steps:
      - pre-steps
      - run:
          name: "Build Velox Minimal"
          command: |
            make min_debug NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=16
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Build Velox With Benchmarks and Without Testing"
          command: |
            make benchmarks-build NUM_THREADS=8 MAX_HIGH_MEM_JOBS=4 MAX_LINK_JOBS=4
          no_output_timeout: 1h
      - post-steps

  linux-adapters:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
      ICU_SOURCE: BUNDLED
      simdjson_SOURCE: BUNDLED
      xsimd_SOURCE: BUNDLED
      DuckDB_SOURCE: SYSTEM
    steps:
      - pre-steps
      - run:
          name: "Install Java for Hadoop"
          command: |
            set -xu
            yum -y install java-1.8.0-openjdk
      - run:
          name: Build including all Benchmarks
          command: |
            EXTRA_CMAKE_FLAGS=(
              "-DVELOX_ENABLE_BENCHMARKS=ON"
              "-DVELOX_ENABLE_ARROW=ON"
              "-DVELOX_ENABLE_PARQUET=ON"
              "-DVELOX_ENABLE_HDFS=ON"
              "-DVELOX_ENABLE_S3=ON"
              "-DVELOX_ENABLE_GCS=ON"
              "-DVELOX_ENABLE_ABFS=ON"
              "-DVELOX_ENABLE_SUBSTRAIT=ON"
              "-DVELOX_ENABLE_REMOTE_FUNCTIONS=ON"
            )
            make release EXTRA_CMAKE_FLAGS="${EXTRA_CMAKE_FLAGS[*]}" NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=8
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Run Unit Tests"
          command: |
            conda init bash
            source ~/.bashrc
            conda create -y --name testbench python=3.7
            conda activate testbench
            pip install https://github.com/googleapis/storage-testbench/archive/refs/tags/v0.36.0.tar.gz
            export LC_ALL=C
            export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk
            export HADOOP_ROOT_LOGGER="WARN,DRFA"
            export LIBHDFS3_CONF=$(pwd)/.circleci/hdfs-client.xml
            export HADOOP_HOME='/usr/local/hadoop'
            export PATH=/usr/local/hadoop/bin:${PATH}
            # The following is used to install Azurite in the CI for running Abfs Hive Connector unit tests.
            # Azurite is an emulator for local Azure Storage development, and it is a required component for running Abfs Hive Connector unit tests.
            # It can be installed using npm. The following is used to install Node.js and npm for Azurite installation.
            curl -sL https://rpm.nodesource.com/setup_10.x | bash -
            yum install -y nodejs
            npm install -g azurite
            cd _build/release && ctest -j 16 -VV --output-on-failure --no-tests=error
          no_output_timeout: 1h
      - post-steps

  linux-presto-fuzzer-run:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
      simdjson_SOURCE: BUNDLED
      xsimd_SOURCE: BUNDLED
      DuckDB_SOURCE: BUNDLED
    steps:
      - fuzzer-run:
          fuzzer_output: "/tmp/fuzzer.log"
          fuzzer_repro: "/tmp/fuzzer_repro"
          fuzzer_name: "Expression"
          fuzzer_exe: "_build/debug/velox/expression/tests/velox_expression_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --lazy_vector_generation_ratio 0.2 \
          --duration_sec 1800 --enable_variadic_signatures \
          --velox_fuzzer_enable_complex_types \
          --velox_fuzzer_enable_column_reuse \
          --velox_fuzzer_enable_expression_reuse \
          --max_expression_trees_per_step 2 \
          --retry_with_try \
          --enable_dereference \
          --logtostderr=1 --minloglevel=0 \
          --repro_persist_path=/tmp/fuzzer_repro"

  linux-spark-fuzzer-run:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
      simdjson_SOURCE: BUNDLED
    steps:
      - fuzzer-run:
          fuzzer_output: "/tmp/spark_fuzzer.log"
          fuzzer_repro: "/tmp/spark_fuzzer_repro"
          fuzzer_name: "Spark"
          fuzzer_exe: "_build/debug/velox/expression/tests/spark_expression_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --duration_sec 600 --logtostderr=1 --minloglevel=0 \
          --repro_persist_path=/tmp/spark_fuzzer_repro"

  linux-spark-aggregate-fuzzer-run:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
      simdjson_SOURCE: BUNDLED
    steps:
      - fuzzer-run:
          fuzzer_output: "/tmp/spark_aggregate_fuzzer.log"
          fuzzer_repro: "/tmp/spark_aggregate_fuzzer_repro"
          fuzzer_name: "SparkAggregate"
          fuzzer_exe: "_build/debug/velox/functions/sparksql/fuzzer/spark_aggregation_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --duration_sec 600 --logtostderr=1 --minloglevel=0 \
          --repro_persist_path=/tmp/spark_aggregate_fuzzer_repro"


  linux-aggregate-fuzzer-run:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
      simdjson_SOURCE: BUNDLED
    steps:
      - fuzzer-run:
          fuzzer_output: "/tmp/aggregate_fuzzer.log"
          fuzzer_repro: "/tmp/aggregate_fuzzer_repro"
          fuzzer_name: "Aggregate"
          fuzzer_exe: "_build/debug/velox/functions/prestosql/fuzzer/velox_aggregation_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --duration_sec 3600 --logtostderr=1 --minloglevel=0 \
          --repro_persist_path=/tmp/aggregate_fuzzer_repro"

  linux-join-fuzzer-run:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
      simdjson_SOURCE: BUNDLED
    steps:
      - fuzzer-run:
          fuzzer_output: "/tmp/join_fuzzer.log"
          fuzzer_repro: "/tmp/join_fuzzer_repro"
          fuzzer_name: "Join"
          fuzzer_exe: "_build/debug/velox/exec/tests/velox_join_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --duration_sec 3600 --logtostderr=1 --minloglevel=0"

  linux-pr-fuzzer-run:
    executor: build
    steps:
      - pre-steps
      - run:
          name: "Get merge base function signatures"
          command: |
            source ~/.bashrc
            conda create -y --name pyveloxenv python=3.7
            conda activate pyveloxenv
            cp ./scripts/signature.py /tmp/signature.py
            pip install deepdiff
            git remote add upstream https://github.com/facebookincubator/velox
            git fetch upstream
            merge_base=$(git merge-base  'upstream/main' `git rev-parse HEAD`) || \
            { echo "::error::Failed to find merge_base"; exit 1; }
            echo "Merge Base: $merge_base"
            git checkout $merge_base
            git submodule update --init --recursive
            LD_LIBRARY_PATH=/usr/local/lib make python-clean
            LD_LIBRARY_PATH=/usr/local/lib make python-build
            python /tmp/signature.py export --spark spark_merge_base_signatures.json
            python /tmp/signature.py export --presto presto_merge_base_signatures.json
      - checkout
      - run:
          name: "Build"
          command: |
            make debug NUM_THREADS=8 MAX_HIGH_MEM_JOBS=4 MAX_LINK_JOBS=4 EXTRA_CMAKE_FLAGS="-DVELOX_ENABLE_ARROW=ON"
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Build and test PyVelox"
          command: |
            conda init bash
            source ~/.bashrc
            conda activate pyveloxenv
            LD_LIBRARY_PATH=/usr/local/lib make python-test
      - run:
          name: "Check and create bias function signatures"
          command: |
            source ~/.bashrc
            conda activate pyveloxenv
            pip install deepdiff
            python ./scripts/signature.py export --presto presto_pr_signatures.json
            python ./scripts/signature.py export --spark spark_pr_signatures.json
            if python ./scripts/signature.py bias presto_merge_base_signatures.json presto_pr_signatures.json /tmp/presto_bias_functions 2>&1 > /tmp/presto-err-message; \
            then echo "Presto signature check success" ; else echo "Presto signature check failed" > /tmp/presto-signature-error-code ; fi
            if python ./scripts/signature.py bias spark_merge_base_signatures.json spark_pr_signatures.json /tmp/spark_bias_functions ; \
            then echo "Spark signature check success"; else echo "Spark signature check failed" > /tmp/spark-signature-error-code ; fi

      - store_artifacts:
          path: 'presto_merge_base_signatures.json'
      - store_artifacts:
          path: 'presto_pr_signatures.json'
      - store_artifacts:
          path: 'spark_merge_base_signatures.json'
      - store_artifacts:
          path: 'spark_pr_signatures.json'
      - fuzzer-run:
          fuzzer_output: "/tmp/fuzzer.log"
          fuzzer_repro: "/tmp/fuzzer_repro"
          fuzzer_name: "Expression Bias Run"
          fuzzer_exe: "if [ -f /tmp/presto_bias_functions ]; then _build/debug/velox/expression/tests/velox_expression_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --lazy_vector_generation_ratio 0.2 \
          --assign_function_tickets  $(cat /tmp/presto_bias_functions) \
          --duration_sec 3600 --enable_variadic_signatures \
          --velox_fuzzer_enable_complex_types \
          --velox_fuzzer_enable_column_reuse \
          --velox_fuzzer_enable_expression_reuse \
          --max_expression_trees_per_step 2 \
          --retry_with_try \
          --enable_dereference \
          --logtostderr=1 --minloglevel=0 \
          --repro_persist_path=/tmp/fuzzer_repro ; fi"

      - fuzzer-run:
          fuzzer_output: "/tmp/spark_fuzzer.log"
          fuzzer_repro: "/tmp/spark_fuzzer_repro"
          fuzzer_name: "Spark Bias Run"
          fuzzer_exe: "if [ -f /tmp/spark_bias_functions ];  then _build/debug/velox/expression/tests/spark_expression_fuzzer_test"
          fuzzer_args: " --seed ${RANDOM} --duration_sec 3600 --logtostderr=1 --minloglevel=0 \
                --assign_function_tickets  $(cat /tmp/spark_bias_functions) \
                --repro_persist_path=/tmp/spark_fuzzer_repro ; fi"

      - run:
          name: "Surface only Presto function signature errors if any"
          command: |
              if [ -f /tmp/presto-signature-error-code ]; then \
              echo "Incompatible changes have been made to function signatures:\n"; \
              cat /tmp/presto-err-message ; \
              exit 1 ; \
              fi


workflows:

  longer-fuzzer:
    when: << pipeline.parameters.run-longer-expression-fuzzer >>
    jobs:
      - linux-pr-fuzzer-run

  shorter-fuzzer:
    unless: << pipeline.parameters.run-longer-expression-fuzzer >>
    jobs:
      - linux-pr-fuzzer-run
