# Copyright (c) Facebook, Inc. and its affiliates.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

version: 2.1

workflows:
  version: 2
  dist-compile:
    jobs:
      - linux-build
      - linux-build-options
      - linux-adapters
      - macos-build
      - format-check
      - header-check
      - linux-benchmarks-basic
      - linux-benchmarks-basic-dedicated

  # Daily documentation update
  nightly:
    triggers:
      - schedule:
         cron: "0 3 * * *"
         filters:
           branches:
             only:
               - main
    jobs:
      - doc-gen-job
      - linux-presto-fuzzer-run
      - linux-spark-fuzzer-run
      - linux-aggregate-fuzzer-run
      - docker-compose-ubuntu-cpp
      - docker-compose-centos-cpp
      - docker-compose-presto-native

  # Hourly build on weekdays
  weekday:
    triggers:
      - schedule:
          cron: "0 0,4,8,12,16,20 * * 1-5"
          filters:
            branches:
              only:
                - main
    jobs:
      - linux-build
      - linux-build-release
      - linux-build-options
      - linux-adapters
      - macos-build

commands:
  update-submodules:
    steps:
      - run:
          name: "Update Submodules"
          command: |
            git submodule sync --recursive
            git submodule update --init --recursive

  setup-environment:
    steps:
      - run:
          name: "Setup Environment"
          command: |
            # Calculate ccache key.
            git show -s --format=%cd --date="format:%Y%m%d" $(git merge-base origin/main HEAD) | tee merge-base-date

            # Set up xml gtest output.
            mkdir -p /tmp/test_xml_output/
            echo "export XML_OUTPUT_FILE=\"/tmp/test_xml_output/\"" >> $BASH_ENV

            # Set up ccache configs.
            mkdir -p .ccache
            echo "export CCACHE_DIR=$(realpath .ccache)" >> $BASH_ENV
            ccache -sz -M 5Gi
            if [ -e /opt/rh/gcc-toolset-9/enable ]; then
              source /opt/rh/gcc-toolset-9/enable
            fi
      - restore_cache:
          name: "Restore CCache Cache"
          keys:
            - velox-ccache-debug-{{ arch }}-{{ checksum "merge-base-date" }}

  pre-steps:
    steps:
      - checkout
      - update-submodules
      - setup-environment

  post-steps:
    steps:
      - save_cache:
          name: "Save CCache Cache"
          key: velox-ccache-debug-{{ arch }}-{{ checksum "merge-base-date" }}
          paths:
            - .ccache/
      - store_artifacts:
          path: '_build/debug/.ninja_log'
      - store_test_results:
          path: '/tmp/test_xml_output/'

  build-benchmarks:
    steps:
      - run:
          name: "Build Benchmarks"
          command: |
            make benchmarks-basic-build NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=8
            ccache -s

  run-benchmarks:
    steps:
      - run:
          name: "Run Benchmarks"
          command: |
            # get to the directory with benchmarks
            cd scripts/veloxbench/veloxbench

            # setup .conbench file
            touch .conbench
            echo "url: $CONBENCH_URL" >> .conbench
            echo "email: $CONBENCH_EMAIL" >> .conbench
            echo "password: $CONBENCH_PASSWORD" >> .conbench
            echo "host_name: $CONBENCH_HOST" >> .conbench

            # Figure out the run name and run reason
            if [[ $CIRCLE_BRANCH == 'main' ]]; then
              # Currently, the names of runs to be included in Conbench history must
              # start with 'commit:'
              # (https://github.com/conbench/conbench/issues/350)
              # This way we can keep track of performance over time on the main branch
              # separately from pull request branches and manual runs.

              run_name="commit: $(git rev-parse HEAD)"
              run_reason='commit'
            else
              run_name="pull request $CIRCLE_PR_NUMBER: $(git rev-parse HEAD)"
              run_reason='pull request'
            fi

            conbench cpp-micro --run-name="$run_name" --run-reason="$run_reason"

executors:
  build:
    docker:
      - image : ghcr.io/facebookincubator/velox-dev:circleci-avx
    resource_class: 2xlarge
    environment:
        CC:  /opt/rh/gcc-toolset-9/root/bin/gcc
        CXX: /opt/rh/gcc-toolset-9/root/bin/g++
        VELOX_DEPENDENCY_SOURCE: BUNDLED
  check:
    docker:
      - image : ghcr.io/facebookincubator/velox-dev:check-avx
  doc-gen:
    docker:
      - image : ghcr.io/facebookincubator/velox-dev:circleci-avx

jobs:
  macos-build:
    macos:
      xcode: "12.5.1"
    resource_class: large
    steps:
      - checkout
      - update-submodules
      - restore_cache:
          name: "Restore Dependency Cache"
          # The version number in the key can be incremented
          # to manually avoid the case where bad dependencies
          # are cached, and has no other meaning.
          # If you update it, be sure to update save_cache too.
          key: velox-circleci-macos-deps-v1-{{ checksum ".circleci/config.yml" }}-{{ checksum "scripts/setup-macos.sh" }}
      - run:
          name: "Install dependencies"
          command: |
            set -xu
            if [[ ! -e ~/deps ]]; then
              mkdir ~/deps ~/deps-src
              curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C ~/deps
              PATH=~/deps/bin:${PATH} DEPENDENCY_DIR=~/deps-src INSTALL_PREFIX=~/deps PROMPT_ALWAYS_RESPOND=n ./scripts/setup-macos.sh
              rm -rf ~/deps/.git ~/deps/Library/Taps/  # Reduce cache size by 70%.
            fi
      - save_cache:
          name: "Save Dependency Cache"
          # The version number in the key can be incremented
          # to manually avoid the case where bad dependencies
          # are cached, and has no other meaning.
          # If you update it, be sure to update restore_cache too.
          key: velox-circleci-macos-deps-v1-{{ checksum ".circleci/config.yml" }}-{{ checksum "scripts/setup-macos.sh" }}
          paths:
            - ~/deps
      - run:
          name: "Calculate merge-base date for CCache"
          command: git show -s --format=%cd --date="format:%Y%m%d" $(git merge-base origin/main HEAD) | tee merge-base-date
      - restore_cache:
          name: "Restore CCache cache"
          keys:
            - velox-ccache-debug-{{ arch }}-{{ checksum "merge-base-date" }}
      - run:
          name: "Build on MacOS"
          command: |
            export PATH=~/deps/bin:~/deps/opt/bison/bin:~/deps/opt/flex/bin:${PATH}
            mkdir -p .ccache
            export CCACHE_DIR=$(pwd)/.ccache
            ccache -sz -M 5Gi
            export OPENSSL_ROOT_DIR=$(brew --prefix openssl@1.1)
            cmake -B _build/debug -GNinja -DTREAT_WARNINGS_AS_ERRORS=1 -DENABLE_ALL_WARNINGS=1 -DCMAKE_BUILD_TYPE=Debug -DCMAKE_PREFIX_PATH=~/deps -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DFLEX_INCLUDE_DIR=~/deps/opt/flex/include
            ninja -C _build/debug
            ccache -s
          no_output_timeout: 1h
      - save_cache:
          name: "Save CCache cache"
          key: velox-ccache-debug-{{ arch }}-{{ checksum "merge-base-date" }}
          paths:
            - .ccache/

  linux-build:
    executor: build
    steps:
      - pre-steps
      - run:
          name: "Build"
          command: |
            make debug NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=8 EXTRA_CMAKE_FLAGS="-DVELOX_ENABLE_ARROW=ON"
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Build and Test PyVelox"
          command: |
            conda init bash
            source ~/.bashrc
            conda create -y --name pyveloxenv python=3.7
            conda activate pyveloxenv
            LD_LIBRARY_PATH=/usr/local/lib make python-test
      - run:
          name: "Run Unit Tests"
          command: |
            cd _build/debug && ctest -j 16 -VV --output-on-failure
          no_output_timeout: 1h
      - store_test_results:
          path: /tmp/test_xml_output/
      - run:
          name: "Run Fuzzer Tests"
          # Run fuzzer using the built executable - we do this instead of make
          # since currently make fuzzertest tends to rebuild the project.
          command: |
            mkdir -p /tmp/fuzzer_repro/
            chmod -R 777 /tmp/fuzzer_repro
            _build/debug/velox/expression/tests/velox_expression_fuzzer_test \
                --seed 123456 \
                --enable_variadic_signatures \
                --velox_fuzzer_enable_complex_types \
                --lazy_vector_generation_ratio 0.2 \
                --velox_fuzzer_enable_column_reuse \
                --velox_fuzzer_enable_expression_reuse \
                --duration_sec 60 \
                --logtostderr=1 \
                --minloglevel=0 \
                --repro_persist_path=/tmp/fuzzer_repro \
            && echo -e "\n\nFuzzer run finished successfully."
          no_output_timeout: 5m
      - store_artifacts:
          path: '/tmp/fuzzer_repro'
      - run:
         name: "Run Example Binaries"
         command: |
           find _build/debug/velox/examples/ -maxdepth 1 -type f -executable -exec "{}" \;
      - post-steps

  linux-build-release:
    executor: build
    steps:
      - pre-steps
      - run:
          name: Build
          command: |
            make release NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=8
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Run Unit Tests"
          command: |
            cd _build/release && ctest -j 16 -VV --output-on-failure
          no_output_timeout: 1h
      - post-steps

  linux-benchmarks-basic:
    executor: build
    environment:
      CONBENCH_URL: "https://velox-conbench.voltrondata.run/"
      CONBENCH_HOST: "CircleCI-runner"
      LINUX_DISTRO: "centos"
      VELOX_DEPENDENCY_SOURCE: SYSTEM
    steps:
      - pre-steps
      - build-benchmarks
      - run:
          name: "Install benchmark dependencies"
          command: |
            # upgrade python to 3.8 for this job
            yum install -y python38
            pip3.8 install -r scripts/benchmark-requirements.txt
      - run-benchmarks
      # TODO: Disabling conbench github notifications for now until results are more stable.
      #- run:
      #  name: "Analyze Benchmark Regressions and Post to Github"
      #    command: |
      #      export GITHUB_APP_PRIVATE_KEY=$(echo $GITHUB_APP_PRIVATE_KEY_ENCODED | base64 -d)
      #      python3.8 scripts/benchmark-github-status.py --z-score-threshold 50
      - post-steps

  linux-benchmarks-basic-dedicated:
    machine:
      image: ubuntu-2004:current
    resource_class: 2xlarge
    environment:
      CONBENCH_URL: "https://velox-conbench.voltrondata.run/"
      CONBENCH_HOST: "CircleCI-runner-dedicated"
      LINUX_DISTRO: "ubuntu"
      VELOX_DEPENDENCY_SOURCE: BUNDLED
      BASELINE_OUTPUT_PATH: "/tmp/baseline_output/"
      TARGET_OUTPUT_PATH: "/tmp/target_output/"
    steps:
      - checkout
      - update-submodules
      - run:
          name: "Setup Ubuntu"
          command: |
            sudo ./scripts/setup-ubuntu.sh
      - setup-environment
      - build-benchmarks
      # TODO: For now we just compare the target binary with itself, until we
      # stabilize benchmark runs. We should eventually have two different
      # set of binaries.
      - run:
          name: "Run Benchmarks - Baseline"
          command: |
            ./scripts/benchmark-runner.py run \
                --bm_estimate_time \
                --bm_max_secs 10 \
                --bm_max_trials 10000 \
                --output_path ${BASELINE_OUTPUT_PATH}
      - run:
          name: "Run Benchmarks - Target"
          command: |
            ./scripts/benchmark-runner.py run \
                --bm_estimate_time \
                --bm_max_secs 10 \
                --bm_max_trials 10000 \
                --output_path ${TARGET_OUTPUT_PATH}
      - run:
          name: "Benchmark Summary"
          command: |
            ./scripts/benchmark-runner.py compare \
                --baseline_path ${BASELINE_OUTPUT_PATH} \
                --target_path ${TARGET_OUTPUT_PATH} || true
      - post-steps

  # Build with different options
  linux-build-options:
    executor: build
    steps:
      - pre-steps
      - run:
          name: "Build Velox Minimal"
          command: |
            make min_debug NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=16
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Build Velox Without Testing"
          command: |
            make clean
            make debug EXTRA_CMAKE_FLAGS="-DVELOX_BUILD_TESTING=OFF" NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=16
            ccache -s
          no_output_timeout: 1h
      - post-steps

  linux-adapters:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
    steps:
      - pre-steps
      - run:
          name: "Install Adapter Dependencies"
          command: |
            mkdir ~/adapter-deps ~/adapter-deps/install
            source /opt/rh/gcc-toolset-9/enable
            set -xu
            DEPENDENCY_DIR=~/adapter-deps PROMPT_ALWAYS_RESPOND=n ./scripts/setup-adapters.sh
      - run:
          name: "Install Minio Server"
          command: |
            set -xu
            cd ~/adapter-deps/install/bin/
            wget https://dl.min.io/server/minio/release/linux-amd64/archive/minio-20220526054841.0.0.x86_64.rpm
            rpm -i minio-20220526054841.0.0.x86_64.rpm
            rm minio-20220526054841.0.0.x86_64.rpm
      - run:
          name: "Install Hadoop Dependency"
          command: |
            set -xu
            yum -y install java-1.8.0-openjdk
      - run:
          name: Build including all Benchmarks
          command: |
            make release EXTRA_CMAKE_FLAGS="-DVELOX_ENABLE_BENCHMARKS=ON -DVELOX_ENABLE_ARROW=ON -DVELOX_ENABLE_PARQUET=ON -DVELOX_ENABLE_HDFS=ON -DVELOX_ENABLE_S3=ON -DVELOX_ENABLE_SUBSTRAIT=ON" AWSSDK_ROOT_DIR=~/adapter-deps/install NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=8
            ccache -s
          no_output_timeout: 1h
      - run:
          name: "Run Unit Tests"
          command: |
            export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk
            export HADOOP_ROOT_LOGGER="WARN,DRFA"
            export LIBHDFS3_CONF=$(pwd)/.circleci/hdfs-client.xml
            export HADOOP_HOME='/usr/local/hadoop'
            export PATH=~/adapter-deps/install/bin:/usr/local/hadoop/bin:${PATH}
            cd _build/release && ctest -j 16 -VV --output-on-failure
          no_output_timeout: 1h
      - post-steps

  linux-presto-fuzzer-run:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
    steps:
      - pre-steps
      - run:
          name: Build
          command: |
            make debug NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=8
            ccache -s
          no_output_timeout: 1h
      - run:
          # Run Fuzzer, save the output to /tmp/fuzzer.log, and upload the file
          # as job artifact to make it convenient for users to inspect it -
          # these logs can also be quite large. Always prints the last 1k lines to
          # the job output for context.
          name: "Run Fuzzer Tests"
          command: |
            echo -e "The logs will be saved to \"/tmp/fuzzer.log\" and uploaded" \
                    "as a job artifact (check the \"Artifacts\" tab above)."
            _build/debug/velox/expression/tests/velox_expression_fuzzer_test \
                --seed ${RANDOM} \
                --lazy_vector_generation_ratio 0.2 \
                --duration_sec 600 \
                --enable_variadic_signatures \
                --velox_fuzzer_enable_complex_types \
                --velox_fuzzer_enable_column_reuse \
                --velox_fuzzer_enable_expression_reuse \
                --logtostderr=1 \
                --minloglevel=0 \
              2>&1 | tee /tmp/fuzzer.log || ( \
                tail -n 1000 /tmp/fuzzer.log;
                echo "FAIL: Fuzzer run failed";
                exit 1; \
              )
            echo -e "\n\nFuzzer run finished successfully."
          no_output_timeout: 20m
      - store_artifacts:
          path: '/tmp/fuzzer.log'
      - post-steps

  linux-spark-fuzzer-run:
    executor: build
    environment:
      VELOX_DEPENDENCY_SOURCE: SYSTEM
    steps:
      - pre-steps
      - run:
          name: Build
          command: |
            make debug NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=8
            ccache -s
          no_output_timeout: 1h
      - run:
          # Run Spark Fuzzer, save the output to /tmp/spark_fuzzer.log, and upload the file
          # as job artifact to make it convenient for users to inspect it -
          # these logs can also be quite large. Always prints the last 1k lines to
          # the job output for context.
          name: "Run Spark Fuzzer Tests"
          command: |
            echo -e "The logs will be saved to \"/tmp/spark_fuzzer.log\" and uploaded" \
                    "as a job artifact (check the \"Artifacts\" tab above)."
            _build/debug/velox/expression/tests/spark_expression_fuzzer_test \
                --seed ${RANDOM} \
                --duration_sec 600 \
                --logtostderr=1 \
                --minloglevel=0 \
              2>&1 | tee /tmp/spark_fuzzer.log || ( \
                tail -n 1000 /tmp/spark_fuzzer.log;
                echo "FAIL: Fuzzer run failed";
                exit 1; \
              )
            echo -e "\n\nSpark Fuzzer run finished successfully."
          no_output_timeout: 20m
      - store_artifacts:
          path: '/tmp/spark_fuzzer.log'
      - post-steps

  linux-aggregate-fuzzer-run:
    executor: build
    steps:
      - pre-steps
      - run:
          name: Build
          command: |
            make debug NUM_THREADS=16 MAX_HIGH_MEM_JOBS=8 MAX_LINK_JOBS=8
            ccache -s
          no_output_timeout: 2h
      - run:
          # Run Aggregate Fuzzer, save the output to /tmp/aggregate_fuzzer.log, and upload the file
          # as job artifact to make it convenient for users to inspect it -
          # these logs can also be quite large. Always prints the last 1k lines to
          # the job output for context.
          name: "Run Aggregate Fuzzer Tests"
          command: |
            echo -e "The logs will be saved to \"/tmp/aggregate_fuzzer.log\" and uploaded" \
                    "as a job artifact (check the \"Artifacts\" tab above)."
            _build/debug/velox/exec/tests/velox_aggregation_fuzzer_test \
                --seed ${RANDOM} \
                --duration_sec 3600 \
                --logtostderr=1 \
                --minloglevel=0 \
              2>&1 | tee /tmp/aggregate_fuzzer.log || ( \
                tail -n 1000 /tmp/aggregate_fuzzer.log;
                echo "FAIL: Aggregate Fuzzer run failed";
                exit 1; \
              )
            echo -e "\n\nAggregate Fuzzer run finished successfully."
          no_output_timeout: 120m
      - store_artifacts:
          path: '/tmp/aggregate_fuzzer.log'
      - post-steps

  format-check:
    executor: check
    steps:
      - checkout
      - run:
          name: Check formatting
          command: |
            if ! make format-check; then
              make format-fix
              echo -e "\n==== Apply using:"
              echo "patch -p1 \<<EOF"
              git --no-pager diff
              echo "EOF"
              false
            fi

  header-check:
    executor: check
    steps:
      - checkout
      - run:
          name: Check license headers
          command: |
            if ! make header-check; then
              make header-fix
              echo -e "\n==== Apply using:"
              echo "patch -p1 \<<EOF"
              git --no-pager diff
              echo "EOF"
              false
            fi

  doc-gen-job:
    executor: doc-gen
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints:
            - "ed:40:13:bc:d0:3d:28:26:98:cb:90:31:cc:d3:f1:6b"
      - run:
          name: "Build docs and update gh-pages"
          command: |
            git config --global user.email "velox@users.noreply.github.com"
            git config --global user.name "velox"
            git checkout main
            make -C velox/docs html
            git checkout gh-pages
            cp -R velox/docs/_build/html/* docs
            git add docs
            if [ -n "$(git status --porcelain)" ]
            then
              git commit -m "Update documentation"
              git push
            fi

  docker-compose-ubuntu-cpp:
    machine: # Use machine executor type to use docker-compose
      image: ubuntu-2204:2022.10.1 # Ubuntu 22.04
    resource_class: 2xlarge
    steps:
      - checkout
      - update-submodules
      - run:
          name: "Build images for ubuntu-CPP declared in docker-compose.yml"
          command: docker-compose build ubuntu-cpp
      - run:
          name: "Run ubuntu-cpp image"
          command: docker-compose run -e NUM_THREADS=16 --rm ubuntu-cpp

  docker-compose-centos-cpp:
    machine: # Use machine executor type to use docker-compose
      # Ubuntu 22.04 is the base image but we use centos 8 on
      # the docker-compose container. There are no centos on
      # circle-ci base images
      image: ubuntu-2204:2022.10.1
    resource_class: 2xlarge
    steps:
      - checkout
      - update-submodules
      - run:
          name: "Build images for centos-cpp declared in docker-compose.yml"
          command: docker-compose build centos-cpp
      - run:
          name: "Run centos-cpp image"
          command: docker-compose run -e NUM_THREADS=16 --rm centos-cpp

  docker-compose-presto-native:
    machine: # Use machine executor type to use docker-compose
      image: ubuntu-2204:2022.10.1
    resource_class: 2xlarge
    environment:
      PRESTODB_REPOSITORY: https://github.com/prestodb/presto
    steps:
      - run:
          name: "Checkout prestodb"
          command: git clone git@github.com:prestodb/presto.git
      - run:
          name: "Update presto-native to latest Velox"
          command: |
            cd presto
            git submodule update --init --recursive
            cd presto-native-execution
            git submodule update --remote --merge
      - run:
          name: "Build presto-native container"
          command: |
            git config --global user.email "velox@users.noreply.github.com"
            git config --global user.name "velox"
            cd presto/presto-native-execution
            make runtime-container
